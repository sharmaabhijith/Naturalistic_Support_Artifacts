# -*- coding: utf-8 -*-
"""GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A2x9HthTxAVVjGVfhFExV2N21e18M24N

## **TrojAI Inc. Project**

![Status](https://img.shields.io/static/v1.svg?label=Status&message=Running&color=red)
[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12zKxVdXI6B8n27FWnwlYi_YdZaavCZyI?usp=sharing) 

![References](https://img.shields.io/static/v1.svg?label=Motivation&message=References&color=green)

# **Generative Adversarial Network**
Training GAN to produce naturalistic images  

## **Pytorch Implementation**

## **TorchGAN** 
Pytorch library to assist in GAN training

[![GitHub](https://img.shields.io/static/v1.svg?logo=github&label=GitHub&message=Repository&color=lightgrey)](https://github.com/torchgan/torchgan)

## **Dataset Link:** 
#### **Birds-400**
[![Dataset](https://img.shields.io/static/v1.svg?logo=kaggle&label=Source&message=Dataset&color=blue)](https://www.kaggle.com/datasets/gpiosenka/100-bird-species?datasetId=534640&sortBy=voteCount)

Train Images=5800 / Test Images=2000 | Categories=400

## **Contributor:** 

*Implemented by: Abhijith Sharma*

(Not official, likely to have bugs/errors)

## **Setting up the environment**
"""

# Connecting to the drive
from google.colab import drive
drive.mount('/content/drive')

# Providing path to working/project directory
import sys
sys.path.append('/content/drive/MyDrive/SFV')

"""## **Importing Libraries**"""

#import warnings
#warnings.filterwarnings('ignore')
from __future__ import print_function, division

# Python Utility Library
import os
import sys
import cv2
import copy
import math
import time
import shutil
import tarfile
! pip install timm
import timm
from tqdm import tqdm
from glob import glob
from pathlib import Path

from collections import defaultdict

# Data Science Libraries
import numpy as np
import pandas as pd
import seaborn as sns
from PIL import Image
from matplotlib import rc
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib.pyplot import *
from matplotlib.pyplot import figure
from matplotlib.ticker import MaxNLocator
plt.ion()   # interactive mode

# SciKit Learn Libraries 
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

# Pytorch Generic Libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import Adam
import torch.nn.functional as F
from torch.optim import lr_scheduler
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torch.utils.data import RandomSampler
from torch.utils.data.sampler import SubsetRandomSampler

# Pytorch Vision Libraries 
import torchvision
import torchvision.utils as vutils
import torchvision.transforms as T
from torchvision.utils import make_grid
from torchvision.datasets import ImageFolder
from torchvision.datasets.utils import download_url
from torchvision import datasets, models, transforms
from torchvision.models import resnet18, resnet

# Intializing the GPU/CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# check whether torchgan is installed or not
try:
    import torchgan

    print(f"Existing TorchGAN {torchgan.__version__} installation found")
except ImportError:
    import subprocess
    import sys

    subprocess.check_call([sys.executable, "-m", "pip", "install", "torchgan"])
    import torchgan

    print(f"Installed TorchGAN {torchgan.__version__}")

# Importing torchGAN Libraries
import torchgan
from torchgan.models import *
from torchgan.trainer import Trainer
from torchgan.losses import *

# Setting up the seed for consistent reproducibility
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)

"""## **Dataset Formation for Train/Test**"""

# Path to Train/Val/Test dataset
PATCH_SIZE = 128 # choose the desired size for generated output of GAN
MAIN_DIR = '/content/drive/MyDrive/SFV/'
DIR_TRAIN = MAIN_DIR + 'Data/train/'
DIR_VAL = MAIN_DIR + 'Data/valid/'
DIR_TEST = MAIN_DIR + 'Data/test/'
FAKE_PATH = MAIN_DIR + 'Fake_Images/Img_' + str(PATCH_SIZE) +'/'
MODEL_PATH = MAIN_DIR + 'Model/GAN_' + str(PATCH_SIZE) +'/'
EMBED_PATH = MAIN_DIR + 'Vec_Embed/' + str(PATCH_SIZE) +'/'

"""Exploring Dataset"""

classes = os.listdir(DIR_TRAIN)
print("Total Classes: ",len(classes))

#Counting total train, valid & test images

train_count = 0
valid_count = 0
test_count = 0
#for _class in classes:
#   train_count += len(os.listdir(DIR_TRAIN + _class))
    #valid_count += len(os.listdir(DIR_VAL + _class))
    #test_count += len(os.listdir(DIR_TEST + _class))

#print("Total train images: ",train_count)
#print("Total valid images: ",valid_count)
#print("Total test images: ",test_count)

"""Creating Data loader """

invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.5, 1/0.5, 1/0.5 ]),
                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ], std = [ 1., 1., 1. ]),])
# Train/Val/Test dataset
trans = transforms.Compose([transforms.Resize((128, 128)),transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
train_dataset = ImageFolder(root = DIR_TRAIN, transform = trans)

#Data Loader  -  using Sampler (YT Video)
train_random_sampler = RandomSampler(train_dataset)

#Shuffle Argument is mutually exclusive with Sampler!
train_dataloader = DataLoader(dataset = train_dataset, batch_size = 16, sampler = train_random_sampler, num_workers = 2)

"""## **Training GAN**"""

# Declare the GAN network
## Choose the desired size for generated output of GAN
dcgan_network = {
    "generator": {
        "name": DCGANGenerator,
        "args": {
            "encoding_dims": 128,
            "out_channels": 3,
            "out_size": PATCH_SIZE,  
            "step_channels": 64,
            "nonlinearity": nn.LeakyReLU(0.2),
            "last_nonlinearity": nn.Tanh(),
        },
        "optimizer": {"name": Adam, "args": {"lr": 0.001, "betas": (0.5, 0.999)}},
    },
    "discriminator": {
        "name": DCGANDiscriminator,
        "args": {
            "in_channels": 3,
            "in_size": PATCH_SIZE,
            "step_channels": 64,
            "nonlinearity": nn.LeakyReLU(0.2),
            "last_nonlinearity": nn.LeakyReLU(0.2),
        },
        "optimizer": {"name": Adam, "args": {"lr": 0.003, "betas": (0.5, 0.999)}},
    },
}

# Wasserstein Loss for training
wgangp_losses = [
    WassersteinGeneratorLoss(),
    WassersteinDiscriminatorLoss(),
    WassersteinGradientPenalty(),
]


# Training the network
trainer = Trainer(dcgan_network, wgangp_losses, sample_size=16, epochs=300, device=device, checkpoints=MODEL_PATH, recon=FAKE_PATH)
#trainer(train_dataloader)

"""## **Output Visualization**"""

# Grab a batch of real images from the dataloader
real_batch = next(iter(train_dataloader))

# Plot the real images
plt.figure(figsize=(10, 10))
plt.subplot(1, 2, 1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(
    np.transpose(
        vutils.make_grid(
            real_batch[0].to(device)[:64], padding=5, normalize=True
        ).cpu(),
        (1, 2, 0),
    )
)

# Plot the fake images from the last epoch
plt.subplot(1, 2, 2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(plt.imread("{}/epoch{}_generator.png".format(trainer.recon, 300)))
plt.show()

image = Image.open(FAKE_PATH+'epoch300_generator.png')
plt.imshow(image)
tr = T.Compose([T.Resize(128), T.ToTensor()])
ten = tr(image)
plt.imshow(ten.permute(1,2,0).numpy())

"""## **Generating suitable artifacts**"""

# Loading trained Generator
model_path = MODEL_PATH + '4.model'
trainer.load_model(model_path)
netG = trainer.generator
netG.eval()

# Trial and Error for finding suitable artifacts
rx = torch.randn(1,128)
latent_embed =  torch.tensor(rx, device=device)
fake = netG(latent_embed)
fake = invTrans(fake[0])
plt.imshow(fake.permute(1,2,0).detach().cpu().numpy())

FILE_PATH = EMBED_PATH + 'yellow_2.pt'
torch.save(latent_embed, FILE_PATH)

FILE_PATH = EMBED_PATH + 'black_1.pt'
l = torch.load(FILE_PATH)
fake = netG(l)
fake = invTrans(fake[0])
plt.imshow(fake.permute(1,2,0).detach().cpu().numpy())

