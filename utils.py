# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I1rhagZ10fsRIxt4IUW_uTjgW0DP5CLJ
"""

# Python Utility Library
import os
import sys
import copy
import math
import time
import cv2
import shutil
import tarfile
from tqdm import tqdm
from glob import glob
from pathlib import Path

from collections import defaultdict

# Data Science Libraries
import numpy as np
import pandas as pd
import seaborn as sns
from PIL import Image
from matplotlib import rc
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib.pyplot import *
from matplotlib.pyplot import figure
from matplotlib.ticker import MaxNLocator
plt.ion()   # interactive mode

# SciKit Learn Libraries 
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

# Pytorch Generic Libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.optim import lr_scheduler
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler

# Pytorch Vision Libraries 
import torchvision
import torchvision.utils as vutils
import torchvision.transforms as T
from torchvision.datasets import ImageFolder
from torchvision.datasets.utils import download_url
from torchvision import datasets, models, transforms

# Adversarial attack library in PyTorch
import torchattacks

# Intializing the GPU/CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Setting up the seed for consistent reproducibility
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)

trans_totensor = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

trans_norm = transforms.Compose([
    transforms.Normalize((0.5, 0.5, 0.5),
                         (0.5, 0.5, 0.5))
])

inv_trans_patch = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.5, 1/0.5, 1/0.5 ]),
                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ], std = [ 1., 1., 1. ]),])

inv_trans_norm = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.5, 1/0.5, 1/0.5 ]),
                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ], std = [ 1., 1., 1. ]),])

# Helper functions that use OpenCV and Torchvision to load  and show images:
def load_image(img_path, resize=True):
  img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
  if resize:
    img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)
  return img

def show_image(img_path):
  img = load_image(img_path)
  plt.imshow(img)
  plt.axis('off')

def show_image_grid(image_paths):
  images = [load_image(img) for img in image_paths]
  images = torch.as_tensor(images)
  images = images.permute(0, 3, 1, 2)
  grid_img = torchvision.utils.make_grid(images, nrow=11)
  plt.figure(figsize=(24, 12))
  plt.imshow(grid_img.permute(1, 2, 0))
  plt.axis('off')


def imshow_old(inp, title=None):
    """Imshow for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    plt.xticks([])
    plt.yticks([])
    plt.imshow(inp)
    if title is not None:
    
        plt.title(title)
#    plt.pause(0.001)  # pause a bit so that plots are updated

"""### Natural Training"""

def natural_train(epochs, cnn_model, train_loaders, optimizer, scheduler, criterion, save_path, trans_norm, norm=True):

  correct = 0
  total = 0
  # Get model into the training model 
  cnn_model.train()
  for e in range(epochs):
  # Load data from data loader
    for batch_idx, (image, label) in enumerate(train_loaders):
      # Assigning computational node to the data and
      image, label = Variable(image), Variable(label)
      # Get data and model onto GPU if available
      image = image.to(device)
      label = label.cuda(device)
      cnn_model = cnn_model.to(device)
      # Normalise the images
      if (norm==True):
        image = trans_norm(image)
      # Erase all previous gradient
      optimizer.zero_grad()
      # Predict output
      output = cnn_model(image)
      # the class with the highest energy is what we choose as prediction
      _, predicted = torch.max(output.data, 1)
      # Calculate loss based on prediction
      loss = criterion(output, label)
      # Perform backpropagation
      loss.backward()
      # Update parameters
      optimizer.step()
      
      # Calculate accuracy
      total += label.size(0)
      correct += torch.sum(predicted == label.data)

      if (batch_idx + 1)% 50 == 0:
          print('Train Epoch: {} [{}/{} ({:.0f}%)]\tAccuracy: {:.1f}'.format(
              e, (batch_idx + 1) * len(image), len(train_loaders.dataset),
              100. * (batch_idx + 1) / len(train_loaders), 100*correct/total))
          
    scheduler.step()

  # Saving Trained model
  torch.save(cnn_model.state_dict(), save_path)
  return cnn_model

"""### Natural Testing"""

def natural_test(cnn_model, test_loaders, criterion, load_path, trans_norm, norm=True):
  # Load model
  cnn_model.load_state_dict(torch.load(load_path, map_location=torch.device(device)))
  correct = 0
  total = 0

  # Load data from data loader
  for batch_idx, (image, label) in enumerate(test_loaders):
    # Assigning computational node to the data and
    image, label = Variable(image), Variable(label)
    # Get data and model onto GPU if available
    image = image.to(device)
    label = label.to(device)
    cnn_model = cnn_model.to(device)
    # Normalise the images
    if (norm==True):
      image = trans_norm(image)
    
    with torch.no_grad():
      # Get model into the training model 
      cnn_model.eval()
      # Predict output
      output = cnn_model(image)
      # the class with the highest energy is what we choose as prediction
      _, predicted = torch.max(output.data, 1)
      # Calculate loss based on prediction
      loss = criterion(output, label)
    
    # Calculate accuracy
    total += label.size(0)
    correct += torch.sum(predicted == label.data)

  print('Accuracy: {:.1f}'.format(100*correct/total))

"""### Adversarial Training"""

"""### Adversarial Training"""

def adversarial_train(epochs, cnn_model, train_loaders, val_loaders, optimizer, scheduler, criterion, save_path, attack_type, epsilon, alpha, steps, trans_norm, norm=True):

  # Get model into the training model
  cnn_model.train()
  best_acc = 0
  for e in range(epochs):
    correct = 0
    total = 0
  # Load data from data loader
    for batch_idx, (image, label) in enumerate(train_loaders):
      # Assigning computational node to the data and
      image, label = Variable(image), Variable(label)
      # Get data and model onto GPU if available
      image = image.to(device)
      label = label.cuda(device)
      cnn_model = cnn_model.to(device)
      # Perform PGD attack
      if attack_type=='PGD':
        attack = torchattacks.PGD(cnn_model, eps=epsilon, alpha=alpha, steps=steps, random_start=True)
        image = attack(image, label)
      # Normalise the images
      if (norm==True):
        image = trans_norm(image)
      # Erase all previous gradient
      optimizer.zero_grad()
      # Predict output
      output = cnn_model(image)
      # the class with the highest energy is what we choose as prediction
      _, predicted = torch.max(output.data, 1)
      # Calculate loss based on prediction
      loss = criterion(output, label)
      # Perform backpropagation
      loss.backward()
      # Update parameters
      optimizer.step()

      # Calculate accuracy
      total += label.size(0)
      correct += torch.sum(predicted == label.data)

      if (batch_idx + 1)% 1000 == 0:
          print('Train Epoch: {} [{}/{} ({:.0f}%)]\tAccuracy: {:.1f}'.format(
              e, (batch_idx + 1) * len(image), len(train_loaders.dataset),100. * (batch_idx + 1) / len(train_loaders), 100*correct/total))

    # Validating current model
    total = 0
    correct = 0
    for image,label in val_loaders:
      image = image.to(device)
      label = label.cuda(device)
      cnn_model = cnn_model.to(device)
      # Normalise the images
      #image = trans_norm(image)
      # Perform PGD attack
      if attack_type=='PGD':
        attack = torchattacks.PGD(cnn_model, eps=epsilon, alpha=alpha, steps=steps, random_start=True)
        image = attack(image, label)
      # Normalise the images
      if (norm==True):
        image = trans_norm(image)
      # Erase all previous gradient
      with torch.no_grad():
        # Predict output
        output = cnn_model(image)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(output.data, 1)
      # Calculate accuracy
      total += label.size(0)
      correct += torch.sum(predicted == label.data)

    accuracy = (100*correct)/total
    print(" ")
    print("Validation Accuracy: ",accuracy)
    print(" ")
    # Saving Trained model
    if accuracy > best_acc:
        torch.save(cnn_model.state_dict(), save_path)
    scheduler.step()

  print(correct,total)
  return cnn_model

"""### Adversarial Testing """

def adversarial_test(cnn_model, test_loaders, criterion, load_path, attack_type, epsilon, alpha, steps, trans_norm, norm=True):

  # Load model
  cnn_model.load_state_dict(torch.load(load_path, map_location=torch.device(device)))
  correct = 0
  total = 0
  # Load data from data loader
  for batch_idx, (image, label) in enumerate(test_loaders):
    # Get data and model onto GPU if available
    image = image.to(device)
    label = label.to(device)
    cnn_model = cnn_model.to(device)
    # Perform PGD attack
    if attack_type=='PGD':
      attack = torchattacks.PGD(cnn_model, eps=epsilon, alpha=alpha, steps=steps, random_start=True)
      image = attack(image, label)
    # Normalise the images
    if (norm==True):
      image = trans_norm(image)
    with torch.no_grad():
      # Get model into the training model
      cnn_model.eval()
      # Predict output
      output = cnn_model(image)
      # the class with the highest energy is what we choose as prediction
      _, predicted = torch.max(output.data, 1)

    # Calculate accuracy
    total += label.size(0)
    correct += torch.sum(predicted == label.data)
  accuracy = (100*correct/total).cpu().numpy()
  accuracy=np.round(accuracy,2)
  return accuracy

"""### Support Feature Vector Analysis"""

def support_test(cnn_model, work_dir, test_loaders, criterion, load_path, attack_type, epsilon, alpha, steps, over_pert, model_name, data_name, norm_tol, trans_norm, norm=True):

  # Load model
  cnn_model.load_state_dict(torch.load(load_path, map_location=torch.device(device)))
  
  correct = 0
  total = 0
  # Load data from data loader
  for batch_idx, (image, label) in enumerate(test_loaders):

    # Load patch of respective class
    patch = Image.open(work_dir+"Multi Patch/"+data_name+"/"+model_name+"/"+str(label.cpu().numpy()[0])+"_"+str(int(over_pert*100))+"_"+str(int(norm_tol*255))+"_200_"+model_name+"_lavan.png")
    # Get data and model onto GPU if available
    image = image.to(device)
    label = label.to(device)
    cnn_model = cnn_model.to(device)
    # Attaching support patch to the image
    input_shape = image.data.cpu().numpy().shape
    convert_tensor = transforms.ToTensor()
    patch = convert_tensor(patch)
    patch=patch[None,:]
    ## Using boundary mask generation from utils 
    mask = boundary_mask_generator(input_shape, over_pert)
    mask = torch.FloatTensor(mask)
    patch = patch.to(device)
    mask = mask.to(device)
    ## Applying patch on the image
    image = torch.mul((1-mask),image) + torch.mul(mask,patch)
    # Perform PGD attack
    if attack_type=='PGD':
      attack = torchattacks.PGD(cnn_model, eps=epsilon, alpha=alpha, steps=steps, random_start=True)
      image = attack(image, label)
    # Normalise the images
    if (norm==True):
      image = trans_norm(image)  
    with torch.no_grad():
      # Get model into the training model
      cnn_model.eval()
      # Predict output
      output = cnn_model(image)
      # the class with the highest energy is what we choose as prediction
      _, predicted = torch.max(output.data, 1)

    # Calculate accuracy
    total += label.size(0)
    correct += torch.sum(predicted == label.data)
    accuracy = (100*correct/total).cpu().numpy()
    accuracy=np.round(accuracy,2)
  print('Accuracy: {:.1f}'.format(100*correct/total))
  return accuracy

"""### Saliency Map Gen"""

def saliency(img, model, PATH):
    #we don't need gradients w.r.t. weights for a trained model
    for param in model.parameters():
        param.requires_grad = False
    input=img
    input.unsqueeze_(0)

    #we want to calculate gradient of higest score w.r.t. input
    #so set requires_grad to True for input 
    input.requires_grad = True
    #forward pass to calculate predictions
    preds = model(input)
    score, indices = torch.max(preds, 1)
    #backward pass to get gradients of score predicted class w.r.t. input image
    score.backward()
    #get max along channel axis
    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)
    #normalize to [0..1]
    #slc = (slc - slc.min())/(slc.max()-slc.min())

    #apply inverse transform on image
    with torch.no_grad():
        input_img = inv_normalize(input[0])
    #plot image and its saleincy map
    plt.figure(figsize=(9, 9))
    plt.subplot(1, 2, 1)
    plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))
    plt.xticks([])
    plt.yticks([])
    plt.subplot(1, 2, 2)
    plt.imshow(slc.numpy(), cmap=plt.cm.hot)
    #plt.colorbar(fraction=0.046)
    plt.xticks([])  
    plt.yticks([])
    plt.savefig(PATH)
    plt.show()

"""### Mask Gen"""

def bg_remove_threshold(img, threshold, gauss_k):  # image of shape 16x16x3

  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
  blur = cv2.GaussianBlur(gray, (gauss_k, gauss_k), 0)

  # perform inverse binary thresholding
  (t, maskLayer) = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY)

  maskLayer = (maskLayer / 255).astype(int)
  mask = 1-maskLayer

  return mask

def create_mask(artifact_0_1, IMAGE_SIZE, PATCH_SIZE, location, threshold, gauss_k):

  # Convert artifcat to numpy and then range 0 to 255 for background processing
  artifact_0_255_numpy = artifact_0_1.permute(1,2,0).detach().cpu().numpy()*255
  # Background processing (Thresholding function for removing background to design the patch mask)
  patch_mask = bg_remove_threshold(artifact_0_255_numpy, threshold, gauss_k)
  # Creating full mask for the image for the application of artifact
  mask = np.zeros((3, IMAGE_SIZE, IMAGE_SIZE))
  # Same mask for each channel
  if location == 'top_right':
    mask[0][0:PATCH_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = patch_mask
    mask[1][0:PATCH_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = patch_mask
    mask[2][0:PATCH_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = patch_mask
  elif location == 'top_left':
    mask[0][0:PATCH_SIZE, 0:PATCH_SIZE] = patch_mask
    mask[1][0:PATCH_SIZE, 0:PATCH_SIZE] = patch_mask
    mask[2][0:PATCH_SIZE, 0:PATCH_SIZE] = patch_mask
  elif location == 'bottom_left':
    mask[0][IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, 0:PATCH_SIZE] = patch_mask
    mask[1][IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, 0:PATCH_SIZE] = patch_mask
    mask[2][IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, 0:PATCH_SIZE] = patch_mask
  elif location == 'bottom_right':
    mask[0][IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = patch_mask
    mask[1][IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = patch_mask
    mask[2][IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = patch_mask

  return mask


# Convert vector embedding to the artifact image
def embed_2_artifact(MAIN_DIR, NUM_ARTIFACTS, CNN_MODEL_NAME, netG, bird_comb, tar_class):
  # Import embedding for which Generator produces a relevant bird figure
  PATCH_SIZE = 64
  norm_tol = 20/255
  steps = 200

  # Initialize dummy embedding vector matrix
  embed_vec = torch.zeros((NUM_ARTIFACTS, 1, 128)).to(device)
  # Initialize dummy artifact matrix
  artifact_0_1 = torch.zeros((NUM_ARTIFACTS, 3, PATCH_SIZE, PATCH_SIZE))

  VEC_EMBED_PATH = [MAIN_DIR + 'Embed_Vec/'+ CNN_MODEL_NAME +'/'+ str(tar_class) +'_'+ str(PATCH_SIZE) +'_'+ str(int(norm_tol*255)) +'_'+ str(steps) +bird_comb+ '.pt']
  embed_vec = torch.load(VEC_EMBED_PATH[0])

  for i in range(NUM_ARTIFACTS):
    # Produce artifacts out of imported embedding (netG is pre-trained Generator)
    artifact = netG(embed_vec[i])
    # Inverse standardisation for display (artifact_0_1 is in range 0 to 1)
    artifact_0_1[i] = inv_trans_patch(artifact[0])

  return artifact_0_1



# Preparing the artifcat to be placed on the dataset images
def place_artifact(artifact, location, IMAGE_SIZE, PATCH_SIZE):
  art_image = torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE))
  if location == 'top_right':
    art_image[:, 0:PATCH_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = artifact
  elif location == 'top_left':
    art_image[:, 0:PATCH_SIZE, 0:PATCH_SIZE] = artifact
  elif location == 'bottom_left':
    art_image[:, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, 0:PATCH_SIZE] = artifact
  elif location == 'bottom_right':
    art_image[:, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE, IMAGE_SIZE-PATCH_SIZE:IMAGE_SIZE] = artifact
  return art_image


# Apply single/mulitple artifacts on the image
def apply_artifact(cnn_model, artifact, mask, orient, image, IMAGE_SIZE, PATCH_SIZE):

  image = image.to(device)
  art_image = torch.mul((1-mask),image)
  
  if len(orient)==1:
    art = place_artifact(artifact, orient, IMAGE_SIZE, PATCH_SIZE)
    # Device compatibility
    art = torch.FloatTensor(art)
    art = art.to(device)
    ## Applying patch on the image
    adv_input = adv_input + torch.mul(mask, art)
  elif len(orient)>1:
    for i in range(len(orient)):
      art = place_artifact(artifact[i], orient[i], IMAGE_SIZE, PATCH_SIZE)
      # Device compatibility
      art = torch.FloatTensor(art)
      art = art.to(device)
      ## Applying patch on the image
      art_image = art_image + torch.mul(mask, art)

  return art_image

# Convert vector embedding to the artifact image
def embed_2_artifact(MAIN_DIR, NUM_ARTIFACTS, CNN_MODEL_NAME, netG, bird_comb, tar_class):
  # Import embedding for which Generator produces a relevant bird figure
  PATCH_SIZE = 64
  norm_tol = 20/255
  steps = 200

  # Initialize dummy embedding vector matrix
  embed_vec = torch.zeros((NUM_ARTIFACTS, 1, 128)).to(device)
  # Initialize dummy artifact matrix
  artifact_0_1 = torch.zeros((NUM_ARTIFACTS, 3, PATCH_SIZE, PATCH_SIZE))

  VEC_EMBED_PATH = [MAIN_DIR + 'Embed_Vec/'+ CNN_MODEL_NAME +'/'+ str(tar_class) +'_'+ str(PATCH_SIZE) +'_'+ str(int(norm_tol*255)) +'_'+ str(steps) +bird_comb+ '.pt']
  embed_vec = torch.load(VEC_EMBED_PATH[0])

  for i in range(NUM_ARTIFACTS):
    # Produce artifacts out of imported embedding (netG is pre-trained Generator)
    artifact = netG(embed_vec[i])
    # Inverse standardisation for display (artifact_0_1 is in range 0 to 1)
    artifact_0_1[i] = inv_trans_patch(artifact[0])

  return artifact_0_1


"""### Attack Visual"""

def attack_visual(cnn_model, mask, location, image, img_type, IMAGE_SIZE, PATCH_SIZE, class_labels, ori_class, artifact=None, attack=None, epsilon=None, steps=None, norm=True):

  if img_type == 'image':
    image = trans_totensor(image)
    image=image[None,:]
  cnn_model=cnn_model.to(device)

  # Clean Image
  if artifact==None and attack==None:
    if (norm==True):
      adv_input=trans_norm(image).to(device)
    label = cnn_model(adv_input).data.max(1)[1]
    print("Original Image")
    print("Prediction: ", class_labels[label])
    imshow_old(inv_trans_norm(adv_input).data[0].cpu())
  
  # Only Adversarial Attack
  if artifact==None and attack!=None:
    if attack=='PGD' or attack=='pgd':
      attack = torchattacks.PGD(cnn_model, eps=epsilon, alpha=1/255, steps=steps)
    if attack=='FGSM' or attack=='fgsm':
      attack = torchattacks.FGSM(cnn_model, eps=epsilon)
    if attack=='CW' or attack=='cw':
      attack = torchattacks.attacks.CW(cnn_model, c=0.0001, kappa=0, steps=1000, lr=0.01)
    adv_input = attack(image, torch.tensor([ori_class]).to(device))
    if (norm==True):
      adv_input = trans_norm(adv_input)
    adv_label = cnn_model(adv_input).data.max(1)[1]
    #print("Image After PGD Attack")
    print("Prediction: ", class_labels[adv_label])
    imshow_old(inv_trans_norm(adv_input).data[0].cpu())     

  # Patch attack
  if artifact!=None:
    image = image.to(device)
    adv_input = torch.mul((1-mask),image)
    
    if len(location)==1:
      art_image = place_artifact(artifact, location, IMAGE_SIZE, PATCH_SIZE)
      # Device compatibility
      art_image = torch.FloatTensor(art_image)
      art_image = art_image.to(device)
      ## Applying patch on the image
      adv_input = adv_input + torch.mul(mask, art_image)
    elif len(location)>1:
      for i in range(len(location)):
        art_image = place_artifact(artifact[i], location[i], IMAGE_SIZE, PATCH_SIZE)
        # Device compatibility
        art_image = torch.FloatTensor(art_image)
        art_image = art_image.to(device)
        ## Applying patch on the image
        adv_input = adv_input + torch.mul(mask, art_image)
    
    # Only Patch Attack
    if attack==None:
      if (norm==True):
        adv_input = trans_norm(adv_input)
      adv_label = cnn_model(adv_input).data.max(1)[1]
      #print("Image After Patch Attack")
      print("Prediction: ", class_labels[adv_label])
      imshow_old(inv_trans_norm(adv_input).data[0].cpu())

    # Both Patch and Adversarial Attack
    else:
      if attack=='PGD' or attack=='pgd':
        attack = torchattacks.PGD(cnn_model, eps=epsilon, alpha=1/255, steps=steps)
      if attack=='FGSM' or attack=='fgsm':
        attack = torchattacks.FGSM(cnn_model, eps=epsilon)
      if attack=='CW' or attack=='cw':
        attack = torchattacks.attacks.CW(cnn_model, c=0.0001, kappa=0, steps=1000, lr=0.01)
      adv_input = attack(adv_input, torch.tensor([ori_class]).to(device))
      if (norm==True):
        adv_input = trans_norm(adv_input)
      adv_label = cnn_model(adv_input).data.max(1)[1]
      #print("Image After PGD->Patch Attack")
      print("Prediction: ", class_labels[adv_label])
      imshow_old(inv_trans_norm(adv_input).data[0].cpu())

  return torch.nn.functional.softmax(cnn_model(adv_input).data, dim=1).max()

"""### Artifact Training"""

# Patch Attack Procedure
def patch_attack_proc(image, IMAGE_SIZE, PATCH_SIZE, embed_vec, patch_type, location, mask, cnn_model, netG, ori_class, tar_class, conf_target, max_count):

    cnn_model.eval()
    # Stopping criteria for optimization
    cond = 1
    count = 0
    target_prob = 0
    # Generate artifact from Generator based on updated vector embedding

    while (cond and count < max_count):
      target_prev = target_prob
      count += 1
      artifact_0_1 = torch.zeros((len(location), 3, PATCH_SIZE, PATCH_SIZE))
      embed_vec = Variable(embed_vec, requires_grad=True)

      for i in range(len(location)):
        # Produce artifacts out of imported embedding (netG is pre-trained Generator)
        artifact = netG(embed_vec[i])
        if (patch_type == 'same'):
          artifact = torchvision.transforms.functional.hflip(artifact)
        # Inverse standardisation for display (artifact_0_1 is in range 0 to 1)
        artifact_0_1[i] = inv_trans_patch(artifact[0])

      adv_image = torch.mul((1-mask),image)
      for i in range(len(location)):
        art_image = place_artifact(artifact_0_1[i], location[i], IMAGE_SIZE, PATCH_SIZE)
        # Device compatibility
        art_image = torch.FloatTensor(art_image)
        art_image = art_image.to(device)
        ## Applying patch on the image
        adv_image = adv_image + torch.mul(mask, art_image)
      
      #imshow_old(adv_image[0].detach().cpu())
      adv_image = trans_norm(adv_image)
      #adv_image = Variable(adv_image, requires_grad=True)
      # Prediction
      adv_out = cnn_model(adv_image)
      x_out = F.softmax(adv_out)
    
      if ori_class!=tar_class:
        # Loss for classifying as target class
        Loss_target = adv_out[0][tar_class]
        # Loss for classifying as original class
        Loss_original = adv_out[0][ori_class]
      else:
        Loss_target = adv_out[0][tar_class]
        Loss_original = 0

      # Overall loss
      Loss = Loss_target - Loss_original
      # Backprop loss gradient w.r.t adv_image
      Loss.backward()
      # Gradient calculation
      adv_grad = embed_vec.grad.data
      # Update patch
      with torch.no_grad():
        embed_vec -= adv_grad       
      embed_vec.grad.data.zero_()   
      # Clipping patch if in image domain (network domain is free to have any values)
      embed_vec=torch.clamp(embed_vec, -1, 1)

      # Stopping criteria
      target_prob = x_out.data[0][tar_class]
      cond = target_prob < conf_target
      if (abs(target_prob-target_prev)< 0.0001):
          break

    return adv_image, embed_vec

def training_loop(MAIN_DIR, IMAGE_SIZE, PATCH_SIZE, embed_vec, bird_comb, patch_type, mask, location, CNN_MODEL_NAME, cnn_model, netG, train_loaders, tar_class, Epochs, norm_tol, norm=True):
  
  steps=200

  cnn_model.eval()
  success = 0
  nat_total = 0
  flag_count=0
  print("Training patch of target class: ", tar_class)

  for epoch in range(Epochs):
    print("Epoch: ",epoch,"/",Epochs)

    for batch_idx, (image, label) in enumerate(train_loaders):
      # Sample image and label from dataset
      # Transfer image to GPU
      image = image.to(device)
      label = label.to(device)
      # Make the image a computational graph
      #image, label = Variable(image), Variable(label)
      if(norm==True):
        image_clean=trans_norm(image)
      else:
        image_clean=image
      # Doing prediction on clean data
      cnn_model=cnn_model.to(device)
      prediction = cnn_model(image_clean)
      # only computer adversarial examples on examples that are originally classified correctly 
      if prediction.data.max(1)[1][0] != label.data[0]:
        continue
      # Increase the count of natural accuracy
      nat_total += 1
      # Perform Norm based attack if the image belongs to the class for which patch is being trained 
      if label.data[0]==tar_class:
        flag_count=flag_count+1
        attack = torchattacks.PGD(cnn_model, eps=norm_tol, alpha=1/255, steps=100, random_start=True)
        image = attack(image, label)
      
      image_shape = image.data.cpu().numpy().shape
      # Traning vector embedding for each embedding
      adv_image, embed_vec = patch_attack_proc(image, IMAGE_SIZE, PATCH_SIZE, embed_vec, patch_type, location, mask, cnn_model, netG, label.data[0], tar_class, 0.99, 10000)
      adv_label = cnn_model(adv_image).data.max(1)[1][0]
      ori_label = label.data[0]
      if adv_label == tar_class:
        success=success+1
      if (batch_idx%2000==0):
        print(batch_idx,"/",len(train_loaders)," Percentage Done: ", int(batch_idx/len(train_loaders)*100),"%")
    print("Total_PGD_attack_counts: ", flag_count)

    # Saving vector embedding
    VEC_EMBED_PATH = MAIN_DIR + 'Embed_Vec/'+ CNN_MODEL_NAME +'/'+ str(tar_class) +'_'+ str(PATCH_SIZE) +'_'+ str(int(norm_tol*255)) +'_'+ str(steps) +bird_comb+ '.pt'
    torch.save(embed_vec, VEC_EMBED_PATH)
  
  print("Training completed")


### Artifact Testing

def testing_loop(MAIN_DIR, IMAGE_SIZE, PATCH_SIZE, NUM_ARTIFACTS, n_classes, embed_vec, bird_comb, orient, patch_type, mask, CNN_MODEL_NAME, cnn_model, netG, attack_mag, steps):

  cnn_model.eval()
  # Per Class results array initialization
  TOTAL_NUM_PER_CLS = []
  ## Result with Naturalistic Support Artifact (NSA)
  NATURAL_CORRECT_W_NSA = []
  ADVERSARIAL_CORRECT_W_NSA = []
  ## Result without Naturalistic Support Artifact (NSA)
  NATURAL_CORRECT_WO_NSA = []
  ADVERSARIAL_CORRECT_WO_NSA = []

  # Location to test dataset
  test_datasets = ImageFolder('./data/test', trans_totensor)

  for cls in range(n_classes):
    print("Class: ",cls+1,"/",n_classes)
    # Class-specific data-loader generation
    targets = torch.tensor(test_datasets.targets)
    target_idx = (targets==cls).nonzero()
    sampler = torch.utils.data.sampler.SubsetRandomSampler(target_idx)
    test_loaders = DataLoader(test_datasets, batch_size = 1, sampler=sampler, num_workers = 2)
    # Trained Artifacts
    artifact_0_1 = embed_2_artifact(MAIN_DIR, NUM_ARTIFACTS, CNN_MODEL_NAME, netG, bird_comb, tar_class = cls)
    # Metric Tracking
    TOTAL_NUM_PER_CLS.append(len(test_loaders))
    NAT_SUCCESS_W_NSA = 0
    ADVER_SUCCESS_W_NSA = 0
    NAT_SUCCESS_WO_NSA = 0
    ADVER_SUCCESS_WO_NSA = 0

    for batch_idx, (image, label) in enumerate(test_loaders):
      # Sample image and label from dataset
      # Transfer image to GPU
      image = image.to(device)
      label = label.to(device)

      #### --------------------------- WITHOUT ARTIFACT --------------------------------------- ####
      ## ------------ NO ATTACK ----------------- ##
      #### Doing prediction on unattacked data
      clean_image=trans_norm(image)
      cnn_model=cnn_model.to(device)
      clean_label = cnn_model(clean_image).data.max(1)[1][0]
      #### only computer adversarial examples on examples that are originally classified correctly
      if clean_label == label.data[0]:
        # Increase the count of natural accuracy
        NAT_SUCCESS_WO_NSA = NAT_SUCCESS_WO_NSA + 1
      ## ------------ PERFORM PGD ATTACK ------------ ##
      attack = torchattacks.PGD(cnn_model, eps = attack_mag, steps = steps, alpha = 1/255,  random_start=True)
      adv_image = attack(image, label)
      adv_image = trans_norm(adv_image)
      #### Doing prediction on attacked data
      adv_label = cnn_model(adv_image).data.max(1)[1][0]
      if adv_label == label.data[0]:
        # Increase the count of adversarial accuracy
        ADVER_SUCCESS_WO_NSA = ADVER_SUCCESS_WO_NSA + 1

      #### --------------------------- WITH ARTIFACT ---------------------------------------####
      ## Apply Artifact
      art_image = apply_artifact(cnn_model, artifact_0_1, mask, orient, image, IMAGE_SIZE, PATCH_SIZE)
      ## ------------ NO ATTACK ----------------- ##
      #### Doing prediction on unattacked data
      clean_art_image=trans_norm(art_image)
      cnn_model=cnn_model.to(device)
      clean_label = cnn_model(clean_art_image).data.max(1)[1][0]
      #### only computer adversarial examples on examples that are originally classified correctly
      if clean_label == label.data[0]:
        # Increase the count of natural accuracy
        NAT_SUCCESS_W_NSA = NAT_SUCCESS_W_NSA + 1
      ## ------------ PERFORM PGD ATTACK ------------ ##
      attack = torchattacks.PGD(cnn_model, eps = attack_mag, steps = steps, alpha = 1/255, random_start=True)
      adv_art_image = attack(art_image, label)
      adv_art_image = trans_norm(adv_art_image)
      #### Doing prediction on attacked data
      adv_label = cnn_model(adv_art_image).data.max(1)[1][0]
      if adv_label == label.data[0]:
        # Increase the count of adversarial accuracy
        ADVER_SUCCESS_W_NSA = ADVER_SUCCESS_W_NSA + 1

    print("Updating metrics")
    # Update metric list
    NATURAL_CORRECT_W_NSA.append(NAT_SUCCESS_W_NSA)
    ADVERSARIAL_CORRECT_W_NSA.append(ADVER_SUCCESS_W_NSA)
    NATURAL_CORRECT_WO_NSA.append(NAT_SUCCESS_WO_NSA)
    ADVERSARIAL_CORRECT_WO_NSA.append(ADVER_SUCCESS_WO_NSA)

  return NATURAL_CORRECT_W_NSA, ADVERSARIAL_CORRECT_W_NSA, NATURAL_CORRECT_WO_NSA, ADVERSARIAL_CORRECT_WO_NSA, TOTAL_NUM_PER_CLS



### Result Logging
def result_log(RES_SAVE_PATH, ROWS, COLS, NATURAL_CORRECT_W_NSA, ADVERSARIAL_CORRECT_W_NSA, NATURAL_CORRECT_WO_NSA, ADVERSARIAL_CORRECT_WO_NSA, TOTAL_NUM_PER_CLS):

  result_df = pd.DataFrame(index=ROWS, columns=COLS)

  NATURAL_ACCURACY_W_NSA = [i / j for i, j in zip(NATURAL_CORRECT_W_NSA, TOTAL_NUM_PER_CLS)]
  ADVERSARIAL_ACCURACY_W_NSA = [i / j for i, j in zip(ADVERSARIAL_CORRECT_W_NSA, TOTAL_NUM_PER_CLS)]
  NATURAL_ACCURACY_WO_NSA = [i / j for i, j in zip(NATURAL_CORRECT_WO_NSA, TOTAL_NUM_PER_CLS)]
  ADVERSARIAL_ACCURACY_WO_NSA = [i / j for i, j in zip(ADVERSARIAL_CORRECT_WO_NSA, TOTAL_NUM_PER_CLS)]

  OVERALL_NATURAL_ACCURACY_W_NSA = 0
  OVERALL_ADVERSARIAL_ACCURACY_W_NSA = 0
  OVERALL_NATURAL_ACCURACY_WO_NSA = 0
  OVERALL_ADVERSARIAL_ACCURACY_WO_NSA = 0

  for i in range (len(ROWS)-1):
    OVERALL_NATURAL_ACCURACY_W_NSA = OVERALL_NATURAL_ACCURACY_W_NSA + (NATURAL_ACCURACY_W_NSA[i]*TOTAL_NUM_PER_CLS[i])/sum(TOTAL_NUM_PER_CLS)
    OVERALL_ADVERSARIAL_ACCURACY_W_NSA = OVERALL_ADVERSARIAL_ACCURACY_W_NSA + (ADVERSARIAL_ACCURACY_W_NSA[i]*TOTAL_NUM_PER_CLS[i])/sum(TOTAL_NUM_PER_CLS)
    OVERALL_NATURAL_ACCURACY_WO_NSA = OVERALL_NATURAL_ACCURACY_WO_NSA + (NATURAL_ACCURACY_WO_NSA[i]*TOTAL_NUM_PER_CLS[i])/sum(TOTAL_NUM_PER_CLS)
    OVERALL_ADVERSARIAL_ACCURACY_WO_NSA = OVERALL_ADVERSARIAL_ACCURACY_WO_NSA + (ADVERSARIAL_ACCURACY_WO_NSA[i]*TOTAL_NUM_PER_CLS[i])/sum(TOTAL_NUM_PER_CLS)

  NATURAL_ACCURACY_W_NSA.append(OVERALL_NATURAL_ACCURACY_W_NSA)
  ADVERSARIAL_ACCURACY_W_NSA.append(OVERALL_ADVERSARIAL_ACCURACY_W_NSA)
  NATURAL_ACCURACY_WO_NSA.append(OVERALL_NATURAL_ACCURACY_WO_NSA)
  ADVERSARIAL_ACCURACY_WO_NSA.append(OVERALL_ADVERSARIAL_ACCURACY_WO_NSA)
  TOTAL_NUM_PER_CLS.append(sum(TOTAL_NUM_PER_CLS))

  result_df['NATURAL_ACCURACY_W_NSA'] = NATURAL_ACCURACY_W_NSA
  result_df['ADVERSARIAL_ACCURACY_W_NSA'] = ADVERSARIAL_ACCURACY_W_NSA
  result_df['NATURAL_ACCURACY_WO_NSA'] = NATURAL_ACCURACY_WO_NSA
  result_df['ADVERSARIAL_ACCURACY_WO_NSA'] = ADVERSARIAL_ACCURACY_WO_NSA
  result_df['TOTAL_NUM_PER_CLS'] = TOTAL_NUM_PER_CLS
    
  print(result_df.head())
  result_df.to_csv(RES_SAVE_PATH)

  return OVERALL_NATURAL_ACCURACY_W_NSA, OVERALL_ADVERSARIAL_ACCURACY_W_NSA, OVERALL_NATURAL_ACCURACY_WO_NSA, OVERALL_ADVERSARIAL_ACCURACY_WO_NSA
